
Data mining (рус. добыча данных, интеллектуальный анализ данных, глубинный анализ данных) — собирательное название, используемое для обозначения совокупности методов обнаружения в данных ранее неизвестных, нетривиальных, практически полезных и доступных интерпретации знаний, необходимых для принятия решений в различных сферах человеческой деятельности. Термин введён Григорием Пятецким-Шапиро в 1989 году[1][2][3].

Английское словосочетание «data mining» пока не имеет устоявшегося перевода на русский язык. При передаче на русском языке используются следующие словосочетания[4]: просев информации, добыча данных, извлечение данных, а также интеллектуальный анализ данных[5][6][7]. Более полным и точным является словосочетание «обнаружение знаний в базах данных» (англ. knowledge discovery in databases, KDD).

Основу методов data mining составляют всевозможные методы классификации, моделирования и прогнозирования, основанные на применении деревьев решений, искусственных нейронных сетей, генетических алгоритмов, эволюционного программирования, ассоциативной памяти, нечёткой логики. К методам data mining нередко относят статистические методы (дескриптивный анализ, корреляционный и регрессионный анализ, факторный анализ, дисперсионный анализ, компонентный анализ, дискриминантный анализ, анализ временных рядов, анализ выживаемости, анализ связей). Такие методы, однако, предполагают некоторые априорные представления об анализируемых данных, что несколько расходится с целями data mining (обнаружение ранее неизвестных нетривиальных и практически полезных знаний).

Одно из важнейших назначений методов data mining состоит в наглядном представлении результатов вычислений (визуализация), что позволяет использовать инструментарий data mining людьми, не имеющими специальной математической подготовки.

Применение статистических методов анализа данных требует хорошего владения теорией вероятностей и математической статистикой.

Методы data mining (или, что то же самое, knowledge discovery in data, сокращённо KDD) лежат на стыке баз данных, статистики и искусственного интеллекта[8].

Область data mining началась с семинара, проведённого Григорием Пятецким-Шапиро в 1989 году.[1]

Ранее, работая в компании GTE Labs, Григорий Пятецкий-Шапиро заинтересовался вопросом: можно ли автоматически находить определённые правила, чтобы ускорить некоторые запросы к крупным базам данных. Тогда же было предложено два термина — data mining («добыча данных»[9]) и knowledge discovery in data (который следует переводить как «открытие знаний в базах данных»).

В 1993 году вышла первая рассылка «Knowledge Discovery Nuggets», а в 1994 году был создан один из первых сайтов по data mining.

Первоначально задача ставится следующим образом:

Необходимо разработать методы обнаружения знаний, скрытых в больших объёмах исходных «сырых» данных. В текущих условиях глобальной конкуренции именно найденные закономерности (знания) могут быть источником дополнительного конкурентного преимущества.

Что означает «скрытые знания»? Это должны быть обязательно знания:

Эти требования во многом определяют суть методов data mining и то, в каком виде и в каком соотношении в технологии data mining используются системы управления базами данных, статистические методы анализа и методы искусственного интеллекта.

Методы data mining могут быть применены как для работы с большими данными, так и для обработки сравнительно малых объемов данных (полученных, например, по результатам отдельных экспериментов, либо при анализе данных о деятельности компании)[источник не указан 1075 дней]. В качестве критерия достаточного количества данных рассматривается как область исследования, так и применяемый алгоритм анализа[источник не указан 1075 дней].

Развитие технологий баз данных сначала привело к созданию специализированного языка — языка запросов к базам данных. Для реляционных баз данных — это язык SQL, который предоставил широкие возможности для создания, изменения и извлечения хранимых данных. Затем возникла необходимость в получении аналитической информации (например, информации о деятельности предприятия за определённый период), и тут оказалось, что традиционные реляционные базы данных, хорошо приспособленные, например, для ведения оперативного учёта на предприятии, плохо приспособлены для проведения анализа. Это привело, в свою очередь, к созданию т. н. «хранилищ данных», сама структура которых наилучшим способом соответствует проведению всестороннего математического анализа.

Знания, добываемые методами data mining, принято представлять в виде закономерностей (паттернов). В качестве таких выступают:

Алгоритмы поиска таких закономерностей находятся на пересечении областей: Искусственный интеллект, Математическая статистика, Математическое программирование, Визуализация, OLAP.

Задачи, решаемые методами data mining, принято разделять на описательные (англ. descriptive) и предсказательные (англ. predictive).

В описательных задачах самое главное — это дать наглядное описание имеющихся скрытых закономерностей, в то время как в предсказательных задачах на первом плане стоит вопрос о предсказании для тех случаев, для которых данных ещё нет.

К описательным задачам относятся:

К предсказательным задачам относятся:

Для задач классификации характерно «обучение с учителем», при котором построение (обучение) модели производится по выборке, содержащей входные и выходные векторы.

Для задач кластеризации и ассоциации применяется «обучение без учителя», при котором построение модели производится по выборке, в которой нет выходного параметра. Значение выходного параметра («относится к кластеру …», «похож на вектор …») подбирается автоматически в процессе обучения.

Для задач сокращения описания характерно отсутствие разделения на входные и выходные векторы. Начиная с классических работ К. Пирсона по методу главных компонент, основное внимание уделяется аппроксимации данных.

Ряд этапов решения задач методами data mining:

Перед использованием алгоритмов data mining необходимо произвести подготовку набора анализируемых данных. Так как ИАД может обнаружить только присутствующие в данных закономерности, исходные данные с одной стороны должны иметь достаточный объём, чтобы эти закономерности в них присутствовали, а с другой — быть достаточно компактными, чтобы анализ занял приемлемое время. Чаще всего в качестве исходных данных выступают хранилища или витрины данных. Подготовка необходима для анализа многомерных данных до кластеризации или интеллектуального анализа данных.

Далее данные фильтруются. Фильтрация удаляет выборки с шумами и пропущенными данными.

Отфильтрованные данные сводятся к наборам признаков (или векторам, если алгоритм может работать только с векторами фиксированной размерности), один набор признаков на наблюдение. Набор признаков формируется в соответствии с гипотезами о том, какие признаки сырых данных имеют высокую прогнозную силу в расчете на требуемую вычислительную мощность для обработки. Например, черно-белое изображение лица размером 100×100 пикселей содержит 10 тыс. бит сырых данных. Они могут быть преобразованы в вектор признаков путём обнаружения в изображении глаз и рта. В итоге происходит уменьшение объёма данных с 10 тыс. бит до списка кодов положения, значительно уменьшая объём анализируемых данных, а значит и время анализа.

Ряд алгоритмов умеют обрабатывать пропущенные данные, имеющие прогностическую силу (например, отсутствие у клиента покупок определенного вида). Скажем, при использовании метода ассоциативных правил (англ.)русск. обрабатываются не векторы признаков, а наборы переменной размерности.

Выбор целевой функции будет зависеть от того, что является целью анализа; выбор «правильной» функции имеет основополагающее значение для успешного интеллектуального анализа данных.

Наблюдения делятся на две категории — обучающий набор и тестовый набор. Обучающий набор используется для «обучения» алгоритма data mining, а тестовый набор — для проверки найденных закономерностей.

